{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19234a7",
   "metadata": {},
   "source": [
    "# Example of building an ml pipeline for return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b040114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from aika import putki\n",
    "from aika.putki import CalendarChecker, IrregularChecker\n",
    "from aika.putki.context import Defaults, GraphContext\n",
    "from aika.putki.graph import Graph, TaskModule\n",
    "from aika.putki.runners import LocalRunner\n",
    "from aika.putki.interface import Dependency\n",
    "from aika.time.calendars import TimeOfDayCalendar, OffsetCalendar\n",
    "from aika.time.time_of_day import TimeOfDay\n",
    "from aika.time.time_range import TimeRange#\n",
    "from aika.time.timestamp import Timestamp\n",
    "from aika.utilities.fin.macd import macd, ewm_volatility\n",
    "from aika.utilities.fin.returns import arithmetic_bar_returns\n",
    "from aika.ml.generators.walkforward import CausalDataSetGenerator\n",
    "from aika.ml.interface import Pipeline, SklearnEstimator, GenericStatelessTransformer, Dataset\n",
    "\n",
    "from aika.datagraph.persistence.hash_backed import HashBackedPersistanceEngine\n",
    "from aika.datagraph.persistence.mongo_backed import MongoBackedPersistanceEngine\n",
    "from pandas_datareader import data\n",
    "import typing as t\n",
    "from pandas.tseries.offsets import BDay\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27889b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = HashBackedPersistanceEngine()\n",
    "context = GraphContext(\n",
    "    defaults=Defaults(\n",
    "        version=\"research\", \n",
    "        persistence_engine=engine, \n",
    "        time_range= TimeRange(\"2010\", \"2020\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_google_finance_data(\n",
    "    tickers : t.List,\n",
    "    time_range,\n",
    "):\n",
    "    df = data.DataReader(list(tickers), \"yahoo\", start=time_range.start, end=time_range.end)\n",
    "    df.index.name = None\n",
    "    df.index = df.index.map(Timestamp) # this ensures it has a timezone.\n",
    "    return df[\"Adj Close\"]\n",
    "\n",
    "close_prices = context.time_series_task(\n",
    "    \"close_prices\",\n",
    "    pull_google_finance_data,\n",
    "    tickers=(\"AAPL\", \"GOOGL\"),\n",
    "    completion_checker=CalendarChecker(\n",
    "        TimeOfDayCalendar(time_of_day=TimeOfDay.from_str(\"00:00 [UTC]\"))\n",
    "    ),\n",
    ")\n",
    "close_prices.run()\n",
    "\n",
    "returns = context.time_series_task(\n",
    "    \"returns\",\n",
    "    arithmetic_bar_returns,\n",
    "    prices=close_prices,\n",
    "    step=1,\n",
    "    time_level=\"end\"\n",
    ")\n",
    "returns.run()\n",
    "returns.read()\n",
    "\n",
    "def risk_adjusted_returns(returns):\n",
    "    return returns.divide(ewm_volatility(returns, span=30).shift(1))\n",
    "\n",
    "risk_adjusted_returns = context.time_series_task(\n",
    "    \"returns.risk_adjusted\",\n",
    "    risk_adjusted_returns,\n",
    "    returns=returns,\n",
    "    time_level=\"end\"\n",
    ")\n",
    "risk_adjusted_returns.run()\n",
    "\n",
    "weekly_returns = context.time_series_task(\n",
    "    \"weekly_returns\",\n",
    "    arithmetic_bar_returns,\n",
    "    prices=close_prices,\n",
    "    step=5,\n",
    "    time_level=\"end\"\n",
    ")\n",
    "weekly_returns.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed82918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macd_multi_horizon(\n",
    "    prices : pd.DataFrame,\n",
    "    horizons : t.List[t.Tuple[int, int]],\n",
    "    vol_span : int\n",
    "):\n",
    "    results = []\n",
    "    for fast, slow in horizons:\n",
    "        foo = macd(prices, fast, slow, vol_span)\n",
    "        foo.columns = pd.MultiIndex.from_tuples(\n",
    "            [(name, fast, slow) for name in prices.columns], \n",
    "            names=(\"Symbols\", \"fast\", \"slow\")\n",
    "        )\n",
    "        results.append(foo)\n",
    "    return pd.concat(results, axis=1)\n",
    "\n",
    "all_macd = context.time_series_task(\n",
    "    \"all_macd\",\n",
    "    macd_multi_horizon,\n",
    "    prices=close_prices,\n",
    "    horizons=(\n",
    "        (10,20),\n",
    "        (20,40),\n",
    "        (40,80),\n",
    "        (80,160),\n",
    "        (160,320)\n",
    "    ),\n",
    "    vol_span=90\n",
    ")\n",
    "all_macd.run()\n",
    "all_macd.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3dbc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine.delete(fitted_models.output, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6bba9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fill_zeros(df : pd.DataFrame):\n",
    "    return df.fillna(0.0)\n",
    "\n",
    "def stack(df : pd.DataFrame):\n",
    "    return df.stack(level=\"Symbols\")\n",
    "\n",
    "def unstack(df : pd.DataFrame):\n",
    "    return df.unstack(level=\"Symbols\")\n",
    "\n",
    "def fit_model(all_macd : pd.DataFrame, returns : pd.DataFrame):\n",
    "    gen = CausalDataSetGenerator(\n",
    "        features=all_macd,\n",
    "        responses=returns,\n",
    "        step_size=100,\n",
    "        window_size=500,\n",
    "        min_periods=300,\n",
    "        strict_step_size=True,\n",
    "        causal_kwargs={\n",
    "            \"index_level\":\"start\",\n",
    "            \"contemp\":True\n",
    "        }\n",
    "    )\n",
    "    results = {}\n",
    "    for dataset in gen:\n",
    "        pipeline = Pipeline(\n",
    "            steps=[\n",
    "                GenericStatelessTransformer(fill_zeros),\n",
    "                GenericStatelessTransformer(stack),\n",
    "                SklearnEstimator(LinearRegression(fit_intercept=True, copy_X=True)),\n",
    "                GenericStatelessTransformer(unstack)\n",
    "            ]\n",
    "        )\n",
    "        pipeline.fit(dataset)\n",
    "        results[dataset.X.index[-1][1]] = pipeline\n",
    "    return pd.Series(results).sort_index()\n",
    "\n",
    "def apply_model(models : pd.Series, data):\n",
    "    points = list(np.searchsorted(\n",
    "        data.index, models.index\n",
    "    ))\n",
    "    results = []\n",
    "    for i,(start,end) in enumerate(zip(points, points[1:] + [data.shape[0]])):\n",
    "        if start != end:\n",
    "            print((start, end))\n",
    "            results.append(\n",
    "                models.iat[i].transform(\n",
    "                    Dataset(X=data.iloc[start:end], y=None)\n",
    "                ).y\n",
    "            )\n",
    "\n",
    "    results = pd.concat(results, axis=0)\n",
    "    return results\n",
    "\n",
    "fitted_models = context.time_series_task(\n",
    "    \"fitted_models\",\n",
    "    fit_model,\n",
    "    all_macd=all_macd,\n",
    "    returns=risk_adjusted_returns,\n",
    "    completion_checker=IrregularChecker()\n",
    ")\n",
    "fitted_models.run()\n",
    "\n",
    "model_outputs = context.time_series_task(\n",
    "    \"model_outputs\",\n",
    "    apply_model,\n",
    "    models=Dependency(fitted_models, lookback=200 * BDay(), inherit_frequency=False),\n",
    "    data=all_macd\n",
    ")\n",
    "model_outputs.run()\n",
    "model_outputs.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f1d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model_outputs.read().copy()\n",
    "r = risk_adjusted_returns.read().copy().droplevel(\"end\")\n",
    "\n",
    "o.columns = pd.MultiIndex.from_tuples([(\"Prediction\", symbol) for symbol in o.columns])\n",
    "r.columns = pd.MultiIndex.from_tuples([(\"Returns\", symbol) for symbol in r.columns])\n",
    "\n",
    "results = pd.concat([o,r], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a63fb86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4e69f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(results.stack(level=1).corr())\n",
    "results.stack(level=1).plot.scatter(x=\"Prediction\", y=\"Returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c72c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Prediction\": o, \"Return\":r.droplevel(\"end\")})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
