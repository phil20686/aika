{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05dda59",
   "metadata": {},
   "source": [
    "# This is an example of building a macd signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from aika import putki\n",
    "from aika.putki import CalendarChecker\n",
    "from aika.putki.context import Defaults, GraphContext\n",
    "from aika.putki.graph import Graph, TaskModule\n",
    "from aika.putki.runners import LocalRunner\n",
    "from aika.putki.interface import Dependency\n",
    "from aika.time.calendars import TimeOfDayCalendar\n",
    "from aika.time.time_of_day import TimeOfDay\n",
    "from aika.time.time_range import TimeRange#\n",
    "from aika.time.timestamp import Timestamp\n",
    "from aika.utilities.fin.macd import macd\n",
    "\n",
    "from aika.datagraph.persistence.hash_backed import HashBackedPersistanceEngine\n",
    "from aika.datagraph.persistence.mongo_backed import MongoBackedPersistanceEngine\n",
    "from pandas_datareader import data\n",
    "import typing as t\n",
    "from pandas.tseries.offsets import BDay\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4b519f",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "### Create an engine\n",
    "We support two kinds of engine at the momemnt, one purely in memory backed by a hash map, and one that stores the data permenantly in a mongodb. You can use either here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68b0172",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = HashBackedPersistanceEngine()\n",
    "# engine = MongoBackedPersistanceEngine(\n",
    "#     pymongo.MongoClient(),\n",
    "#     database_name=\"research_foo3\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023d7372",
   "metadata": {},
   "source": [
    "### Create a context\n",
    "A context is the user interface for creating tasks. It mainly just functinos as a place holder to fill in information that is common to all or nearly all tasks. In this case, the code version, the storage engine, and the time_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8331a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = GraphContext(\n",
    "    defaults=Defaults(\n",
    "        version=\"research\", \n",
    "        persistence_engine=engine, \n",
    "        time_range= TimeRange(\"2018\", \"2020\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbf0e9e",
   "metadata": {},
   "source": [
    "## Create your first function. \n",
    "This just uses pandas datareader project to pull some stock data from yahoo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb2f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_google_finance_data(\n",
    "    tickers : t.List,\n",
    "    time_range,\n",
    "):\n",
    "    df = data.DataReader(list(tickers), \"yahoo\", start=time_range.start, end=time_range.end)\n",
    "    df.index.name = None\n",
    "    df.index = df.index.map(Timestamp) # this ensures it has a timezone.\n",
    "    return df[\"Adj Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1821d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_google_finance_data([\"AAPL\", \"GOOGL\"], TimeRange(\"2018\", \"2020\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcceeb6",
   "metadata": {},
   "source": [
    "Now instead we can create a task to do that. The task needs a name, the function to run, and the parameters, finally, because this is a \"source\" node of the graph, we must specify a completion checker. A completion checker specified the expected index for the data, in this case, we are saying that we expect it to have a value every buisiness day at midnight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c10989",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_prices = context.time_series_task(\n",
    "    \"close_prices\",\n",
    "    pull_google_finance_data,\n",
    "    tickers=(\"AAPL\", \"GOOGL\"),\n",
    "    completion_checker=CalendarChecker(\n",
    "        TimeOfDayCalendar(time_of_day=TimeOfDay.from_str(\"00:00 [UTC]\"))\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12653bad",
   "metadata": {},
   "source": [
    "Before we run the task it will evaluate as \"not complete\", and after we run it it will evaluate as \"complete\". Further, we pull the data from the engine and display it with the read command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9122e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(close_prices.complete())\n",
    "close_prices.run()\n",
    "display(close_prices.complete())\n",
    "close_prices.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a9d7a",
   "metadata": {},
   "source": [
    "## Lets do some macd using the library functions\n",
    "\n",
    "Macd calculatsions are index preserving, as are most time series operations, so here we do not need to specify a completion checkier, it is inferred from its parent task, in this case close prices. Note as well here that we can store two different datasets in the same \"node\" of the data graph, all that is required is that their parameters are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "macd_one = context.time_series_task(\n",
    "    \"macd\",\n",
    "    macd,\n",
    "    prices=close_prices,\n",
    "    fast_span=10,\n",
    "    slow_span=20,\n",
    "    vol_span=30\n",
    ")\n",
    "\n",
    "macd_two = context.time_series_task(\n",
    "    \"macd\",\n",
    "    macd,\n",
    "    prices=close_prices,\n",
    "    fast_span=20,\n",
    "    slow_span=40,\n",
    "    vol_span=60\n",
    ")\n",
    "macd_one.completion_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f00865",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(macd_one.complete())\n",
    "macd_one.run()\n",
    "macd_one.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eda2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(macd_two.complete())\n",
    "macd_two.run()\n",
    "display(macd_two.complete())\n",
    "macd_two.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ac46ee",
   "metadata": {},
   "source": [
    "## Branching Engines\n",
    "\n",
    "Sometimes we will have one engine that already contains the data that we need, and want to run some experiments that run in a different engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84c0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_two = HashBackedPersistanceEngine()\n",
    "macd_three = context.time_series_task(\n",
    "    \"macd\",\n",
    "    macd,\n",
    "    prices=close_prices,\n",
    "    fast_span=20,\n",
    "    slow_span=40,\n",
    "    vol_span=60,\n",
    "    persistence_engine=engine_two\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaaa4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "macd_three.run()\n",
    "display(macd_three.complete())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3ac3af",
   "metadata": {},
   "source": [
    "Now the new data set is in the engine below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d546937",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(engine.exists(macd_three.output))\n",
    "display(engine_two.exists(macd_three.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c372c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(data):\n",
    "    return data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_two = context.static_task(\n",
    "    \"macd.describe\",\n",
    "    describe,\n",
    "    data=macd_two,\n",
    ")\n",
    "describe_two.run()\n",
    "describe_two.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68088d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_three = context.static_task(\n",
    "    \"macd.describe\",\n",
    "    describe,\n",
    "    data=macd_three,\n",
    ")\n",
    "describe_three.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
